[{"title":"Gen8折腾日记.md","url":"/2016/07/Gen8-diary/","content":"前言放假伊始，老大订购了两台服务器，一台是Dell的R630，用于其他老师的实验室计算用途，另一台则是Gen8，并且一口气把想买的配件全部搞回来了，于是在假期的第一周就摸上了这台非常舒适安静的Gen8啦，本文主要写我们的改装计划以及虚拟化的部署过程，而在后面的计划中，我将虚拟服务器的部署过程交给了小朋友们当做练习，让他们熟悉Linux服务器。\n老大有一句话说的特别好，凡是先谈项目需求，对，在列出装机配置之前，我们先来说说这次的需求，其实主要目的就是玩，Chiphell上面有一票子大神们两年来一直在各种折腾Gen8，然后在暑假之前工作室有两位师兄也凑单买了一台普通的Gen8，然后老大表示忍耐不住了，当即决定下单高配版，外加内存硬盘固态全部买齐，给我们这些小弟们玩！不过玩归玩，说到底其实还是利用它的存储，将高清资源集中在一起，方便工作室的小伙伴一起共享。\n\n\n好了，先上配置单！\n\n部署步骤接下来来说说整个的改装和部署过程，由于我们对硬件没有强烈的痴迷，所以只是做了简单的改装。\n\n连接网线接入网络，其中iLO以及一个网口接入内网，将一个网口接入路由器。\n\n\n\n原装服务器有8GB的内存，另外加上1条8GB内存，构成16GB双通道。\n\n\n\n4块西数企业级硬盘，全书放入硬盘笼内。\n\n\n\n将固态硬盘装进光驱位内，然后将Gen8的光驱拆出来，装入后，由于没有螺丝位可以加固，我采用的方案是利用透明胶将其完全的固定，效果还是不错的，然后转接器将光驱的SATA转为标准的SATA，与服务器的配线匹配。\n\n\n\n将SATA线插在下面的SATA接口中，然后4pin的电源公线和母线接紧，然后通过服务器自带的理线孔理线，接上电源线，显示器以及键盘鼠标。\n\n\n\n开机，服务器显示正在初始化中。\n\n\n\nCPU初始化完成后，开始进入HP特有的初始化界面。\n\n\n\n第一步决定先配置磁盘阵列。\n\n\n\n进入HP Smart Storage Administartor。\n\n\n\n\n进入阵列卡管理界面，配置阵列。\n\n\n\n由于在写这篇文章之前我已经配置过一次机械盘，B120i的阵列卡比较低级，只能配置RAID0和RAID1以及RAID10，因此对于4块机械盘配置的是RAID10，SSD就直接RAID0了，SSD也要配置RAID，个人认为原因是在BIOS界面中我们选择的硬盘模式为RAID，在一般的主机中，我们可以选择AHCI或者Legacy作为硬盘的配置模式，而在服务器中，由于有阵列卡，因此会多了一种可以进行配置。\n\n\n\n配置SSD的性能参数，相比于一般的阵列卡来说，比如像LSI MegaRAID 9260 8i，在这里可选的参数就比较少了，没有了如读写策略的配置，不过也够用了。\n\n\n\n配置完毕。\n\n\n\n重启以后进入iLO的网络配置，这个根据工作室内网的规划，决定使用这个10.86.1.8这个地址，进入Network选项卡里面配置。\n\n\n\n将DHCP关掉以免引起冲突，配置DNS名称。\n\n\n\n再次重启后能根据Fn键的提示进入到服务器最重要的环节，也就是它的Intelligent Provisioning，这里有两个部分可以进行选择，分别是硬件维护以及安装系统。\n\n\n\n点开硬件维护的界面看看。\n\n\n\n返回到Intelligent Provisioning的初始界面，选择Configure and Install，进入到安装选项，这里要注意的是选择system software update选择skip update，不然安装时还要与网络上的服务器通信，大大增加安装时间。\n\n\n\n由于老大的需求是要做虚拟化，选择了ESXi5.5，这里要注意的是要选择Customize，然后USB安装。一开始接触这台服务器的时候为了安装虚拟化操作系统还是花费了不少功夫，查了不少文档以及chiphell上面大触们的教程，最终成功的方案是，HPE5.5的iso。ISO下载链接。下载以后不需要刻录成启动盘，直接将ISO放入U盘即可！\n\n\n\n在这一步看到了我们放进去的ISO，双击它，会自动进行挂载，然后在右下角就能看到有继续的过程，因为我在写文章的时候已经安装过一次了，所以就不点了，正常来说安装的时间不到3分钟，我第一次安装的时候试过安装了一个下午都没行，后来才发现是自己把ISO做成了启动盘，后来是重新下载镜像，直接放进去做成功的。\n\n\n\n\n安装完毕后再次重启，就能看到虚拟化底层的界面了。\n\n\n\n接下来随便拿一台同网段的机器，下载vSphere Client 5.5，安装。\n\n\n\n\n安装完毕后就能打开这个界面了，输入给Gen8分配的地址，注意这里不是使用iLO的地址哦，应该这样子说，必须给Gen8这台服务器一个地址，如果需要iLO进行管理，则另外需要给iLO一个地址。\n\n\n\n登录进去以后就能看到vSphere的界面了。\n\n\n\n查看配置，在写文章之前我已经挂载了机械盘进去了，因为光驱和转接头晚了几天到的缘故，现在挂载SSD。\n\n\n\n在配置这里我们能看到有两块本地的存储，我们需要将新增加的SSD初始化进入底层。选择添加存储器。\n\n\n\n接下来就比较简单了，就基本是一路下一步就可以添加好了。\n\n\n\n\n\n\n\n\n最后根据师兄的建议弄了一个和内存大小一样的SSD缓存。\n\n\n\n\n总结：总体来说，这是个最为简单的配置方案，由于还没测试磁盘读写性能怎么样，因此对于BIOS中的设置基本以默认为主，待小朋友把Linux ftp服务器部署好以后再慢慢的测试性能，根据性能可能会不断重新部署ESXi系统，也正好给小朋友们练练手部署这个系统。\n更新\n2025年11月13日注：时光境迁，Gen8放在工作室已经接近10年的时间，目前它仍然投入使用，但是已经开始出现硬件问题，我目前还没排查是否仍然是当初的硬件，估计是需要更换了。\n\n2019年2月19日注：没想到时间过得那么快，Gen8已经在工作室投入生产环境2年多了，这2年多以来，2016-2017年我是比较关注Gen8的使用情况，它作为FTP服务器的备用服务器还是非常的不错的，在我毕业以后，Gen8还发生过硬盘损坏的情况，当时已有备份，所以没有损失，现在据说Gen8是作为数码组存储拍摄的原片的用途，看上去挺好的，希望后面的网管组师弟师妹们能好好利用这台服务器。\n\n\n"},{"title":"dynamic_rnn转nn.GRU详细记录.md","url":"/2020/08/dynamic_rnn-to-nn_gru-record/","content":"今天在将一份tensorflow的代码转为pytorch时遇到的一点困难，经过多次debug以后终于弄清楚了这里应该是如何进行转换的，因此记录下来。\n直接上代码吧，为了确保最终的结果是一致的，这里我将网络层的权重全部初始化为0。\nimport torchimport torch.nn as nnimport numpy as npimport tensorflow as tffrom tensorflow.keras import initializersinput = np.random.rand(3, 1, 5)hidden = np.random.rand(3, 5)print(&quot;input: &quot;, input.shape)print(input)print(&quot;hidden: &quot;, hidden.shape)print(hidden)print(&quot;=&quot;*20, &#x27; tensorflow result &#x27;, &quot;=&quot;*20)# cell with zeros initializercell = tf.compat.v1.nn.rnn_cell.GRUCell(5, kernel_initializer=initializers.Zeros(), bias_initializer=initializers.Zeros())tf_output, tf_state = tf.compat.v1.nn.dynamic_rnn(cell, input, initial_state=hidden)print(tf_output)        # (batch size, time steps, features)print(tf_state)         # (batch size, features) for the final time stepsprint(&#x27;\\n&#x27;)print(&quot;=&quot;*20, &#x27; rnn cell result &#x27;, &quot;=&quot;*20)# rnn cellpytorch_rnn_cell = nn.GRUCell(5, 5)for k, v in pytorch_rnn_cell.state_dict().items():    torch.nn.init.constant_(v, 0)pytorch_input_cell = torch.from_numpy(input).permute(1, 0, 2).float()   # (time steps, batch size, features)pytorch_hidden_cell = torch.from_numpy(hidden).float()                  # (batch size, features)pytorch_output_cell = []for i in range(1):    pytorch_hidden_cell = pytorch_rnn_cell(pytorch_input_cell[i], pytorch_hidden_cell)    pytorch_output_cell.append(pytorch_hidden_cell)print(pytorch_output_cell)print(&#x27;\\n&#x27;)print(&quot;=&quot;*20, &#x27; rnn result &#x27;, &quot;=&quot;*20)# rnnpytorch_rnn = nn.GRU(5, 5)for k, v in pytorch_rnn.state_dict().items():    torch.nn.init.constant_(v, 0)pytorch_input = torch.from_numpy(input).permute(1, 0, 2).float()        # (time steps, batch size, feature size)pytorch_hidden = torch.from_numpy(hidden).unsqueeze(0).float()          # (time steps, batch size, hidden size)pytorch_output, pytorch_state = pytorch_rnn(pytorch_input, pytorch_hidden)print(pytorch_output, pytorch_output.shape)print(pytorch_state, pytorch_state.shape)\n\n最后的结果如下\ninput:  (3, 1, 5)[[[0.98175333 0.59281082 0.47678967 0.70612923 0.73616147]] [[0.8363702  0.85099391 0.75740424 0.30633335 0.20097122]] [[0.60316062 0.21921029 0.16052985 0.25654177 0.40698399]]]hidden:  (3, 5)[[0.46976021 0.19681885 0.59240364 0.79540728 0.27608136] [0.39461795 0.29340918 0.4515729  0.6921841  0.44068605] [0.89315058 0.72514622 0.2925488  0.45433305 0.59910906]]====================  tensorflow result  ====================tf.Tensor([[[0.23488011 0.09840942 0.29620182 0.39770364 0.13804068]] [[0.19730898 0.14670459 0.22578645 0.34609205 0.22034303]] [[0.44657529 0.36257311 0.1462744  0.22716653 0.29955453]]], shape=(3, 1, 5), dtype=float64)tf.Tensor([[0.23488011 0.09840942 0.29620182 0.39770364 0.13804068] [0.19730898 0.14670459 0.22578645 0.34609205 0.22034303] [0.44657529 0.36257311 0.1462744  0.22716653 0.29955453]], shape=(3, 5), dtype=float64)====================  rnn cell result  ====================[tensor([[0.2349, 0.0984, 0.2962, 0.3977, 0.1380],        [0.1973, 0.1467, 0.2258, 0.3461, 0.2203],        [0.4466, 0.3626, 0.1463, 0.2272, 0.2996]], grad_fn=&lt;AddBackward0&gt;)]====================  rnn result  ====================tensor([[[0.2349, 0.0984, 0.2962, 0.3977, 0.1380],         [0.1973, 0.1467, 0.2258, 0.3461, 0.2203],         [0.4466, 0.3626, 0.1463, 0.2272, 0.2996]]], grad_fn=&lt;StackBackward&gt;) torch.Size([1, 3, 5])tensor([[[0.2349, 0.0984, 0.2962, 0.3977, 0.1380],         [0.1973, 0.1467, 0.2258, 0.3461, 0.2203],         [0.4466, 0.3626, 0.1463, 0.2272, 0.2996]]], grad_fn=&lt;StackBackward&gt;) torch.Size([1, 3, 5])Process finished with exit code 0"},{"title":"python中关于传递参数模块argprase的一些小坑.md","url":"/2019/12/argprase_order_record/","content":"今天在写代码的时候遇到了一个关于parser的一些小坑，记录在此备用。\n我们知道在python中可以用argprase来传递一些参数给代码执行，来看下面的例子，假设现在有一个test文件夹，下面有3个python文件，分别用a.py；b.py；c.py来表示，目录树如下。\ntest├── a.py├── b.py├── c.py\n\n每一个的初始代码为一个简单的print函数。\n#a.pydef out_a():    print(&quot;I am a.py&quot;)if __name__ == &#x27;__main__&#x27;:    out_a()\n\n#b.pydef out_b():    print(&quot;I am b.py&quot;)if __name__ == &#x27;__main__&#x27;:    out_b()\n\n#c.pydef out_c():    print(&quot;I am c.py&quot;)if __name__ == &#x27;__main__&#x27;:    out_c()\n\n现在在a.py中引入模块argprase，并定义一些简单的参数，代码如下\nimport argparseparser = argparse.ArgumentParser()parser.add_argument(&#x27;--first_parameter&#x27;, default=&#x27;first&#x27;)parser.add_argument(&#x27;--second_parameter&#x27;, default=&#x27;second&#x27;)parser.add_argument(&#x27;--third_flag&#x27;, action=&#x27;store_true&#x27;)args = parser.parse_args()def out_a():    print(&quot;I am a.py&quot;)if __name__ == &#x27;__main__&#x27;:    out_a()\n\n这里面简单说一下第3个参数，这也是我今天想记录文章的原因，这个参数是argparse里面提供的开关布尔选项，actions记录的是一个动作，意味着在调用这个函数的时候，如果在命令行添加这个参数，则该参数为True，如果不添加这个参数，则该参数为False，归纳起来为如下的两个图。\n这个是没有指定第3个参数的情况\n\n这个是指定第3个参数的情况\n\n对于这种开关布尔选项更为详细的介绍，可以参考知乎问题：Argparse中action的可选参数store_true,store_false到底是什么意思？\n到目前为止没有出现问题，接下来，我希望b.py也使用参数，并且还希望使用a.py里面的函数，因此我对b.py进行如下修改。\nfrom a import out_aimport argparseparser = argparse.ArgumentParser()parser.add_argument(&#x27;--fourth_parameter&#x27;, default=&#x27;fourth&#x27;)parser.add_argument(&#x27;--fifth_parameter&#x27;, default=&#x27;fifth&#x27;)parser.add_argument(&#x27;--sixth_flag&#x27;, action=&#x27;store_true&#x27;)args = parser.parse_args()def out_b():    print(&quot;I am b.py&quot;)if __name__ == &#x27;__main__&#x27;:    out_b()    out_a()\n\n然后同样的，我们分别用两种方式来测试b.py，效果如下。\n这个是不使用参数的情况\n\n这个是使用参数的情况\n\n可以看到报错了，当时我看到这里的时候想了很久，排除了拼写错误的情况以后，观察这里面的输出，发现看到的是a.py当中的3个参数，而不是b.py当中设置的参数，于是我将a.py和b.py的参数表打印出来，看到这样子的结果。\n输出两个python文件的参数表\n\n可以发现尽管我使用的是from a import out_a，但依然引入了a.py当中的参数表，并且后引入的b.py的参数表没有办法覆盖掉。下面在c.py中同样引入3个参数，然后引入b.py的方法，代码如下：\nfrom b import out_bimport argparseparser = argparse.ArgumentParser()parser.add_argument(&#x27;--seventh_parameter&#x27;, default=&#x27;seventh&#x27;)parser.add_argument(&#x27;--eighth_parameter&#x27;, default=&#x27;eighth&#x27;)parser.add_argument(&#x27;--ninth_flag&#x27;, action=&#x27;store_true&#x27;)args = parser.parse_args()print(args)def out_c():    print(&quot;I am c.py&quot;)if __name__ == &#x27;__main__&#x27;:    out_c()    out_b()\n\n效果如下\n不使用任何参数调用c.py\n\n看到有3个参数列表输出就知道c.py的参数也是无效的了，验证一下。\n使用参数调用c.py\n\n解决方案：\n其实只需要将所有的参数表放到同一个文件里面就可以了，比如utils.py，由于这里是同一个文件夹下的3个文件，在import调用的时候就只需要初始化一次所有参数就可以使用了，有点类似于C语言当中的全局变量，因为这个东西排查了一个下午，也是有点恼火了。\n"},{"title":"Hello World","url":"/2016/07/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\n\n\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"}]